{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (4.39.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Number of CUDA devices: 1\n",
      "Number of CUDA devices: 1\n",
      "CUDA Device 0: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "Switched to GPU\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"Number of CUDA devices:\", torch.cuda.device_count())\n",
    "\n",
    "print(\"Number of CUDA devices:\", torch.cuda.device_count())\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(\"CUDA Device {}: {}\".format(i, torch.cuda.get_device_name(i)))\n",
    "\n",
    "# Check for the availability of CUDA-enabled GPU\n",
    "if torch.cuda.is_available():\n",
    "    # Set device to GPU\n",
    "    torch.cuda.set_device(0)\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Switched to GPU\")\n",
    "else:\n",
    "    # Use CPU if no GPU is available\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"No GPU available, using CPU\")\n",
    "\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (2.6.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sentence-transformers) (4.39.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sentence-transformers) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sentence-transformers) (2.2.0+cu121)\n",
      "Requirement already satisfied: numpy in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sentence-transformers) (1.24.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sentence-transformers) (1.10.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sentence-transformers) (0.22.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sentence-transformers) (10.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.12.2)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (2.2.0+cu121)\n",
      "Requirement already satisfied: filelock in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (2023.12.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: summa in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: scipy>=0.19 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from summa) (1.10.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scipy>=0.19->summa) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install summa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judgment dataset size: 7030\n",
      "Summary dataset size: 7030\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from transformers import PegasusTokenizer\n",
    "\n",
    "# Initialize Legal-PEGASUS tokenizer\n",
    "tokenizer = PegasusTokenizer.from_pretrained(\"nsi319/legal-pegasus\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase and remove unnecessary characters or metadata\n",
    "    cleaned_text = text.lower()\n",
    "    cleaned_text = re.sub(r'\\n+', ' ', cleaned_text)  # Remove extra newlines\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)  # Remove extra whitespaces\n",
    "    return cleaned_text.strip()\n",
    "\n",
    "\n",
    "def tokenize_text(text):\n",
    "    # Tokenize text using Legal-PEGASUS tokenizer\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "def load_dataset(folder_path):\n",
    "    dataset = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "            text = preprocess_text(text)\n",
    "            tokens = tokenize_text(text)\n",
    "            dataset.append((tokens, folder_path.split(\"/\")[-1]))  # Pairing text with its folder name (judgment/summary)\n",
    "    return dataset\n",
    "\n",
    "# Example usage\n",
    "judgment_dir = \"judgment\"  # Replace this with the actual path to your judgment folder\n",
    "summary_dir = \"summary\"    # Replace this with the actual path to your summary folder\n",
    "\n",
    "judgment_dataset = load_dataset(judgment_dir)\n",
    "summary_dataset = load_dataset(summary_dir)\n",
    "\n",
    "print(\"Judgment dataset size:\", len(judgment_dataset))\n",
    "print(\"Summary dataset size:\", len(summary_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "def chunk_document_flexible(text, max_chunk_size):\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_size = 0\n",
    "\n",
    "    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', text)  # Split text into sentences\n",
    "    for sentence in sentences:\n",
    "        sentence_size = len(sentence.split())\n",
    "        if current_size + sentence_size > max_chunk_size and current_chunk:\n",
    "            chunks.append(' '.join(current_chunk))\n",
    "            current_chunk = []\n",
    "            current_size = 0\n",
    "        current_chunk.append(sentence)\n",
    "        current_size += sentence_size\n",
    "    if current_chunk:\n",
    "        chunks.append(' '.join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def process_judgment_files(input_folder, output_folder, max_chunk_size):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        input_file_path = os.path.join(input_folder, file_name)\n",
    "        output_base_name = os.path.splitext(file_name)[0] + \"_chunk\"\n",
    "        with open(input_file_path, 'r', encoding='utf-8') as input_file:\n",
    "            text = input_file.read()\n",
    "            text = preprocess_text(text)\n",
    "            chunks = chunk_document_flexible(text, max_chunk_size)\n",
    "            for i, chunk in enumerate(chunks, start=1):\n",
    "                output_file_path = os.path.join(output_folder, f\"{output_base_name}{i}.txt\")\n",
    "                with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "                    output_file.write(chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "judgment_input_folder = \"judgment\"  \n",
    "judgment_output_folder = \"judgment_chunk\" \n",
    "max_chunk_size = 950  \n",
    "\n",
    "process_judgment_files(judgment_input_folder, judgment_output_folder, max_chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import PegasusTokenizer, PegasusForConditionalGeneration\n",
    "\n",
    "def get_embedding(text):\n",
    "    input_ids = tokenizer.encode(text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids)\n",
    "    return output.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "\n",
    "def calculate_mean_cosine_similarity(judgment_embedding, summary_embedding):\n",
    "    similarities = cosine_similarity(judgment_embedding.reshape(1, -1), summary_embedding)\n",
    "    mean_similarity = np.mean(similarities)\n",
    "    return mean_similarity\n",
    "\n",
    "def generate_summary(judgment_chunk, summary_file):\n",
    "    judgment_embedding = get_embedding(judgment_chunk)\n",
    "    \n",
    "    with open(summary_file, 'r', encoding='utf-8') as file:\n",
    "        summary_text = file.read()\n",
    "        summary_text = preprocess_text(summary_text)\n",
    "        summary_embedding = get_embedding(summary_text)\n",
    "    \n",
    "    similarity = calculate_mean_cosine_similarity(judgment_embedding, summary_embedding)\n",
    "    return summary_text if similarity > 0 else \"\"\n",
    "\n",
    "def process_judgment_chunks(judgment_chunk_folder, summary_folder, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    for chunk_file_name in os.listdir(judgment_chunk_folder):\n",
    "        judgment_chunk_path = os.path.join(judgment_chunk_folder, chunk_file_name)\n",
    "        summary_file_name = chunk_file_name.split(\"_\")[0] + \".txt\"\n",
    "        summary_file_path = os.path.join(summary_folder, summary_file_name)\n",
    "        output_file_path = os.path.join(output_folder, chunk_file_name.replace(\"_chunk\", \"_chunksum\"))\n",
    "        \n",
    "        with open(judgment_chunk_path, 'r', encoding='utf-8') as judgment_chunk_file, \\\n",
    "             open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "            judgment_chunk = judgment_chunk_file.read()\n",
    "            summary = generate_summary(judgment_chunk, summary_file_path)\n",
    "            output_file.write(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    cleaned_text = text.lower()  # Convert text to lowercase\n",
    "    cleaned_text = re.sub(r'\\n+', ' ', cleaned_text)  # Remove extra newlines\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)  # Remove extra whitespaces\n",
    "    return cleaned_text.strip()\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process judgment chunks\n",
    "def process_specified_chunks(judgment_chunk_folder, summary_folder, output_folder, chunk_names):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    for chunk_name in chunk_names:\n",
    "        judgment_chunk_file = os.path.join(judgment_chunk_folder, f\"{chunk_name}.txt\")\n",
    "        summary_file = os.path.join(summary_folder, \"1.txt\")  # Assuming all chunks correspond to 1.txt summary\n",
    "        \n",
    "        output_file_path = os.path.join(output_folder, f\"{chunk_name.replace('_chunk', '_chunksum')}.txt\")\n",
    "        \n",
    "        with open(judgment_chunk_file, 'r', encoding='utf-8') as file:\n",
    "            judgment_chunk = file.read()\n",
    "            summary = generate_summary(judgment_chunk, summary_file)\n",
    "            with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "                output_file.write(summary)\n",
    "\n",
    "# Example usage\n",
    "judgment_chunk_folder = \"judgment_chunk\"  # Replace this with the actual path to your judgment chunk folder\n",
    "summary_folder = \"summary\"  # Replace this with the actual path to your summary folder\n",
    "summary_chunk_folder = \"summary_chunk\"  # Replace this with the desired output path for chunked summaries\n",
    "chunk_names = [\"1_chunk1\", \"1_chunk2\", \"1_chunk3\", \"1_chunk4\"]  # Specify the chunk names to be processed\n",
    "\n",
    "process_specified_chunks(judgment_chunk_folder, summary_folder, summary_chunk_folder, chunk_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from summa import summarizer  # Using Summa for final summarization\n",
    "\n",
    "# Initialize the models\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nsi319/legal-pegasus\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"nsi319/legal-pegasus\")\n",
    "sentence_model = SentenceTransformer(\"average_word_embeddings_glove.6B.300d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_cosine_similarity(document_chunk, summary_vectors):\n",
    "    chunk_vector = sentence_model.encode(document_chunk)\n",
    "    # Reshape summary vectors to match the shape of chunk vector\n",
    "    summary_vectors = summary_vectors.reshape(len(summary_vectors), -1)\n",
    "    similarities = cosine_similarity(chunk_vector, summary_vectors)\n",
    "    return np.mean(similarities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate summaries for each chunk\n",
    "# Function to generate summaries for each chunk\n",
    "def generate_chunk_summaries(document_chunks, summary_vectors, model, tokenizer):\n",
    "    chunk_summaries = []\n",
    "    for chunk in document_chunks:\n",
    "        # Encode the chunk text\n",
    "        inputs = tokenizer(chunk, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            # Generate summary\n",
    "            summary_ids = model.generate(inputs.input_ids, num_beams=4, min_length=10, max_length=150, early_stopping=True)\n",
    "            # Decode summary\n",
    "            summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "            chunk_summaries.append(summary)\n",
    "    return chunk_summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate mean cosine similarity\n",
    "def calculate_mean_cosine_similarity(document_chunk, summary_vectors):\n",
    "    chunk_vector = sentence_model.encode([document_chunk])[0]\n",
    "    summary_vectors = np.vstack(summary_vectors)\n",
    "    similarities = cosine_similarity(chunk_vector.reshape(1, -1), summary_vectors)\n",
    "    mean_similarity = np.mean(similarities)\n",
    "    return mean_similarity\n",
    "\n",
    "# Function to generate and save chunk summaries separately\n",
    "def generate_and_save_chunk_summaries(judgment_chunk_folder, summary_folder, output_folder):\n",
    "    for chunk_file_name in os.listdir(judgment_chunk_folder):\n",
    "        if chunk_file_name.endswith(\".txt\"):\n",
    "            with open(os.path.join(judgment_chunk_folder, chunk_file_name), 'r', encoding='utf-8') as f:\n",
    "                document_text = f.read()\n",
    "\n",
    "            # Find the corresponding summary file\n",
    "            summary_file_name = \"1.txt\"  # Assuming all summaries are in the same file for this example\n",
    "            summary_file_path = os.path.join(summary_folder, summary_file_name)\n",
    "\n",
    "            if os.path.exists(summary_file_path):\n",
    "                with open(summary_file_path, 'r', encoding='utf-8') as f:\n",
    "                    summary_text = f.read()\n",
    "\n",
    "                # Preprocess text\n",
    "                document_chunks = document_text.split('\\n')\n",
    "                summary_vectors = sentence_model.encode(summary_text.split('\\n'))\n",
    "\n",
    "                # Generate summaries for each chunk\n",
    "                chunk_summaries = []\n",
    "                for i, chunk in enumerate(document_chunks, start=1):\n",
    "                    similarity = calculate_mean_cosine_similarity(chunk, summary_vectors)\n",
    "                    if similarity > 0:  # If similarity is found\n",
    "                        # Summarize the chunk\n",
    "                        chunk_summary = summarizer.summarize(chunk)\n",
    "                        chunk_summaries.append(chunk_summary)\n",
    "                    else:\n",
    "                        chunk_summaries.append(\"\")  # Empty summary if no similarity is found\n",
    "\n",
    "                # Save each chunk summary separately\n",
    "                for i, summary in enumerate(chunk_summaries, start=1):\n",
    "                    chunk_summary_file_name = f\"{os.path.splitext(chunk_file_name)[0]}_sum{i}.txt\"\n",
    "                    with open(os.path.join(output_folder, chunk_summary_file_name), 'w', encoding='utf-8') as f:\n",
    "                        f.write(summary)\n",
    "            else:\n",
    "                print(f\"No summary found for {chunk_file_name}\")\n",
    "\n",
    "# Paths\n",
    "judgment_chunk_folder = \"judgment_chunk\"  # Folder containing judgment chunks\n",
    "summary_folder = \"summary\"  # Folder containing summary files\n",
    "output_folder = \"summary_chunk_final\"  # Output folder to store chunk summaries separately\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Call the function\n",
    "generate_and_save_chunk_summaries(judgment_chunk_folder, summary_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of files in judgment_chunk: 36469\n",
      "Total number of files in summary_chunk_final: 36469\n",
      "Total number of files in both folders: 72938\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def count_files_in_folder(folder_path):\n",
    "    if not os.path.isdir(folder_path):\n",
    "        return 0\n",
    "    return len([name for name in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, name))])\n",
    "\n",
    "judgment_chunk_path = \"judgment_chunk\"\n",
    "summary_chunk_final_path = \"summary_chunk_final\"\n",
    "\n",
    "judgment_chunk_count = count_files_in_folder(judgment_chunk_path)\n",
    "summary_chunk_final_count = count_files_in_folder(summary_chunk_final_path)\n",
    "\n",
    "total_files_count = judgment_chunk_count + summary_chunk_final_count\n",
    "\n",
    "print(\"Total number of files in judgment_chunk:\", judgment_chunk_count)\n",
    "print(\"Total number of files in summary_chunk_final:\", summary_chunk_final_count)\n",
    "print(\"Total number of files in both folders:\", total_files_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def rename_files_in_folder(folder_path, suffix):\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print(f\"The folder '{folder_path}' does not exist.\")\n",
    "        return\n",
    "    \n",
    "    processed_folder_path = \"processed_\" + os.path.basename(folder_path)\n",
    "    processed_folder_full_path = os.path.join(os.path.dirname(folder_path), processed_folder_path)\n",
    "    os.makedirs(processed_folder_full_path, exist_ok=True)\n",
    "\n",
    "    # Iterate over files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(suffix):\n",
    "            # Extract the prefix and chunk number from the filename\n",
    "            prefix, chunk_number = filename.split('_')[0], filename.split('_')[1]\n",
    "            # Construct the new filename\n",
    "            new_filename = f\"{prefix}_{chunk_number}.{suffix}\"\n",
    "            # Rename the file\n",
    "            os.rename(os.path.join(folder_path, filename), os.path.join(processed_folder_full_path, new_filename))\n",
    "            print(f\"Renamed '{filename}' to '{new_filename}'\")\n",
    "\n",
    "summary_chunk_final_path = \"summary_chunk_final\"\n",
    "suffix = \"sum1.txt\"\n",
    "\n",
    "rename_files_in_folder(summary_chunk_final_path, suffix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files copied successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Source and destination directories\n",
    "source_folder = \"summary_chunk_final\"\n",
    "destination_folder = \"summary_chunk\"\n",
    "\n",
    "# Create the destination folder if it doesn't exist\n",
    "os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "# Iterate over files in the source folder\n",
    "for filename in os.listdir(source_folder):\n",
    "    source_file_path = os.path.join(source_folder, filename)\n",
    "    destination_file_path = os.path.join(destination_folder, filename)\n",
    "    # Copy the file to the destination folder\n",
    "    shutil.copy(source_file_path, destination_file_path)\n",
    "\n",
    "print(\"Files copied successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Path to the folders\n",
    "judgment_chunk_path = \"judgment_chunk\"\n",
    "summary_chunk_final_path = \"summary_chunk_final\"\n",
    "\n",
    "# List all files in the folders\n",
    "judgment_files = sorted(os.listdir(judgment_chunk_path))\n",
    "summary_files = sorted(os.listdir(summary_chunk_final_path))\n",
    "\n",
    "# Initialize lists to store file contents and names\n",
    "judgment_contents = []\n",
    "summary_contents = []\n",
    "judgment_filenames = []\n",
    "summary_filenames = []\n",
    "\n",
    "# Read contents of judgment files and save file names\n",
    "for file in judgment_files:\n",
    "    with open(os.path.join(judgment_chunk_path, file), 'r') as f:\n",
    "        judgment_contents.append(f.read())\n",
    "    judgment_filenames.append(file)\n",
    "\n",
    "# Read contents of summary files and save file names\n",
    "for file in summary_files:\n",
    "    with open(os.path.join(summary_chunk_final_path, file), 'r') as f:\n",
    "        summary_contents.append(f.read())\n",
    "    summary_filenames.append(file)\n",
    "\n",
    "# Create DataFrame\n",
    "data = {\n",
    "    \n",
    "    'judgment': judgment_contents,\n",
    "    'summary_filename': summary_filenames,\n",
    "    'judgment_filename': judgment_filenames,\n",
    "    'summary': summary_contents\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save DataFrame to CSV\n",
    "df.to_csv('output.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judgment</th>\n",
       "      <th>summary_filename</th>\n",
       "      <th>judgment_filename</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>appeal no. 388 of 1960. appeal by special leav...</td>\n",
       "      <td>1000_chunk1_sum1.txt</td>\n",
       "      <td>1000_chunk1.txt</td>\n",
       "      <td>on february 1, 1957, the nomination paper file...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>section 7(d), as it stood at the material time...</td>\n",
       "      <td>1000_chunk2_sum1.txt</td>\n",
       "      <td>1000_chunk2.txt</td>\n",
       "      <td>section 7(d), as it stood at the material time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>varma, however, contends that the service unde...</td>\n",
       "      <td>1000_chunk3_sum1.txt</td>\n",
       "      <td>1000_chunk3.txt</td>\n",
       "      <td>varma, however, contends that the service unde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in that case the appellant who was a contracto...</td>\n",
       "      <td>1000_chunk4_sum1.txt</td>\n",
       "      <td>1000_chunk4.txt</td>\n",
       "      <td>\"it cannot be gainsaid\", observed sinha, j., a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>appeal no. 198 of 1954. appeal from the judgme...</td>\n",
       "      <td>1001_chunk1_sum1.txt</td>\n",
       "      <td>1001_chunk1.txt</td>\n",
       "      <td>this is an appeal from the judgment of the nag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36464</th>\n",
       "      <td>the learned advocate for the appellant therefo...</td>\n",
       "      <td>9_chunk2_sum1.txt</td>\n",
       "      <td>9_chunk2.txt</td>\n",
       "      <td>that the judgment debtor respondent suppressed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36465</th>\n",
       "      <td>in the insolvency court, he set up the plea th...</td>\n",
       "      <td>9_chunk3_sum1.txt</td>\n",
       "      <td>9_chunk3.txt</td>\n",
       "      <td>(2) nothing in this section shall be deemed (a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36466</th>\n",
       "      <td>having thus got over the difficulty in his way...</td>\n",
       "      <td>9_chunk4_sum1.txt</td>\n",
       "      <td>9_chunk4.txt</td>\n",
       "      <td>if the facts proved and found as established a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36467</th>\n",
       "      <td>concealing from a person the knowledge of his ...</td>\n",
       "      <td>9_chunk5_sum1.txt</td>\n",
       "      <td>9_chunk5.txt</td>\n",
       "      <td>the decree holder must have been taking steps ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36468</th>\n",
       "      <td>by the enactment of section 18, the legislatur...</td>\n",
       "      <td>9_chunk6_sum1.txt</td>\n",
       "      <td>9_chunk6.txt</td>\n",
       "      <td>it was urged that the various starting points ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36469 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                judgment  \\\n",
       "0      appeal no. 388 of 1960. appeal by special leav...   \n",
       "1      section 7(d), as it stood at the material time...   \n",
       "2      varma, however, contends that the service unde...   \n",
       "3      in that case the appellant who was a contracto...   \n",
       "4      appeal no. 198 of 1954. appeal from the judgme...   \n",
       "...                                                  ...   \n",
       "36464  the learned advocate for the appellant therefo...   \n",
       "36465  in the insolvency court, he set up the plea th...   \n",
       "36466  having thus got over the difficulty in his way...   \n",
       "36467  concealing from a person the knowledge of his ...   \n",
       "36468  by the enactment of section 18, the legislatur...   \n",
       "\n",
       "           summary_filename judgment_filename  \\\n",
       "0      1000_chunk1_sum1.txt   1000_chunk1.txt   \n",
       "1      1000_chunk2_sum1.txt   1000_chunk2.txt   \n",
       "2      1000_chunk3_sum1.txt   1000_chunk3.txt   \n",
       "3      1000_chunk4_sum1.txt   1000_chunk4.txt   \n",
       "4      1001_chunk1_sum1.txt   1001_chunk1.txt   \n",
       "...                     ...               ...   \n",
       "36464     9_chunk2_sum1.txt      9_chunk2.txt   \n",
       "36465     9_chunk3_sum1.txt      9_chunk3.txt   \n",
       "36466     9_chunk4_sum1.txt      9_chunk4.txt   \n",
       "36467     9_chunk5_sum1.txt      9_chunk5.txt   \n",
       "36468     9_chunk6_sum1.txt      9_chunk6.txt   \n",
       "\n",
       "                                                 summary  \n",
       "0      on february 1, 1957, the nomination paper file...  \n",
       "1      section 7(d), as it stood at the material time...  \n",
       "2      varma, however, contends that the service unde...  \n",
       "3      \"it cannot be gainsaid\", observed sinha, j., a...  \n",
       "4      this is an appeal from the judgment of the nag...  \n",
       "...                                                  ...  \n",
       "36464  that the judgment debtor respondent suppressed...  \n",
       "36465  (2) nothing in this section shall be deemed (a...  \n",
       "36466  if the facts proved and found as established a...  \n",
       "36467  the decree holder must have been taking steps ...  \n",
       "36468  it was urged that the various starting points ...  \n",
       "\n",
       "[36469 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               judgment   summary_filename  \\\n",
      "6108  it is elementary that the primary duty of a co...  1_chunk4_sum1.txt   \n",
      "\n",
      "     judgment_filename                                            summary  \n",
      "6108      1_chunk4.txt  in the above case in arriving at his conclusio...  \n"
     ]
    }
   ],
   "source": [
    "# Assuming you have already created the DataFrame 'df'\n",
    "row = df[df['summary_filename'] == '1_chunk4_sum1.txt']\n",
    "\n",
    "# Printing the row\n",
    "print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judgment</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>appeal no. 388 of 1960. appeal by special leav...</td>\n",
       "      <td>on february 1, 1957, the nomination paper file...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>section 7(d), as it stood at the material time...</td>\n",
       "      <td>section 7(d), as it stood at the material time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>varma, however, contends that the service unde...</td>\n",
       "      <td>varma, however, contends that the service unde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in that case the appellant who was a contracto...</td>\n",
       "      <td>\"it cannot be gainsaid\", observed sinha, j., a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>appeal no. 198 of 1954. appeal from the judgme...</td>\n",
       "      <td>this is an appeal from the judgment of the nag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36464</th>\n",
       "      <td>the learned advocate for the appellant therefo...</td>\n",
       "      <td>that the judgment debtor respondent suppressed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36465</th>\n",
       "      <td>in the insolvency court, he set up the plea th...</td>\n",
       "      <td>(2) nothing in this section shall be deemed (a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36466</th>\n",
       "      <td>having thus got over the difficulty in his way...</td>\n",
       "      <td>if the facts proved and found as established a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36467</th>\n",
       "      <td>concealing from a person the knowledge of his ...</td>\n",
       "      <td>the decree holder must have been taking steps ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36468</th>\n",
       "      <td>by the enactment of section 18, the legislatur...</td>\n",
       "      <td>it was urged that the various starting points ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36469 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                judgment  \\\n",
       "0      appeal no. 388 of 1960. appeal by special leav...   \n",
       "1      section 7(d), as it stood at the material time...   \n",
       "2      varma, however, contends that the service unde...   \n",
       "3      in that case the appellant who was a contracto...   \n",
       "4      appeal no. 198 of 1954. appeal from the judgme...   \n",
       "...                                                  ...   \n",
       "36464  the learned advocate for the appellant therefo...   \n",
       "36465  in the insolvency court, he set up the plea th...   \n",
       "36466  having thus got over the difficulty in his way...   \n",
       "36467  concealing from a person the knowledge of his ...   \n",
       "36468  by the enactment of section 18, the legislatur...   \n",
       "\n",
       "                                                 summary  \n",
       "0      on february 1, 1957, the nomination paper file...  \n",
       "1      section 7(d), as it stood at the material time...  \n",
       "2      varma, however, contends that the service unde...  \n",
       "3      \"it cannot be gainsaid\", observed sinha, j., a...  \n",
       "4      this is an appeal from the judgment of the nag...  \n",
       "...                                                  ...  \n",
       "36464  that the judgment debtor respondent suppressed...  \n",
       "36465  (2) nothing in this section shall be deemed (a...  \n",
       "36466  if the facts proved and found as established a...  \n",
       "36467  the decree holder must have been taking steps ...  \n",
       "36468  it was urged that the various starting points ...  \n",
       "\n",
       "[36469 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming you have already created the DataFrame 'df'\n",
    "df1 = df.drop(columns=['summary_filename', 'judgment_filename'])\n",
    "\n",
    "# Print the modified DataFrame\n",
    "df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'final_dataframe.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3921: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer, AdamW\n",
    "import torch\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Load Legal PEGASUS tokenizer\n",
    "tokenizer = PegasusTokenizer.from_pretrained(\"nsi319/legal-pegasus\")\n",
    "\n",
    "# Prepare data\n",
    "judgments = df1['judgment'].tolist()\n",
    "summaries = df1['summary'].tolist()\n",
    "\n",
    "# Tokenize and encode data\n",
    "input_ids = tokenizer.prepare_seq2seq_batch(judgments, summaries, truncation=True, padding=True, return_tensors='pt')\n",
    "\n",
    "# Load Legal PEGASUS model\n",
    "model = PegasusForConditionalGeneration.from_pretrained(\"nsi319/legal-pegasus\")\n",
    "\n",
    "# Define training arguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:114] data. DefaultCPUAllocator: not enough memory: you tried to allocate 152962072576 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 13\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[0;32m     15\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\models\\pegasus\\modeling_pegasus.py:1352\u001b[0m, in \u001b[0;36mPegasusForConditionalGeneration.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m decoder_input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m decoder_inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1348\u001b[0m         decoder_input_ids \u001b[38;5;241m=\u001b[39m shift_tokens_right(\n\u001b[0;32m   1349\u001b[0m             labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdecoder_start_token_id\n\u001b[0;32m   1350\u001b[0m         )\n\u001b[1;32m-> 1352\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1353\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1362\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1363\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1364\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1365\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1366\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1367\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1368\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1369\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(outputs[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_logits_bias\n\u001b[0;32m   1371\u001b[0m masked_lm_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\models\\pegasus\\modeling_pegasus.py:1196\u001b[0m, in \u001b[0;36mPegasusModel.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1193\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1196\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1197\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1200\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1201\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1202\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1205\u001b[0m \u001b[38;5;66;03m# If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True\u001b[39;00m\n\u001b[0;32m   1206\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(encoder_outputs, BaseModelOutput):\n",
      "File \u001b[1;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\models\\pegasus\\modeling_pegasus.py:740\u001b[0m, in \u001b[0;36mPegasusEncoder.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to specify either input_ids or inputs_embeds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 740\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_scale\n\u001b[0;32m    742\u001b[0m embed_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_positions(input_shape)\n\u001b[0;32m    744\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m embed_pos\n",
      "File \u001b[1;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\functional.py:2237\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2231\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2232\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2233\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2234\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2235\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2236\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:114] data. DefaultCPUAllocator: not enough memory: you tried to allocate 152962072576 bytes."
     ]
    }
   ],
   "source": [
    "num_train_epochs = 2\n",
    "learning_rate = 5e-5\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_train_epochs):\n",
    "    # Train the model\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(**input_ids)\n",
    "    loss = outputs.loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Print elapsed time\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Epoch {epoch + 1}/{num_train_epochs} - Elapsed Time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"./fine_tuned_nsi319_legal_pegasus\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
